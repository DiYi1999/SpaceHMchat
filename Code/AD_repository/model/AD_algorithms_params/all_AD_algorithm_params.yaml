Autoformer: {}
Common_configs:
  AD_threshold:
    description_CN: 异常分数阈值，误差超过这个值就认为是异常
    description_EN: Anomaly Score Threshold, errors exceeding this value are considered
      anomalies
    value: 0.5
  Decompose:
    description_CN: 预处理多尺度分解方法
    description_EN: Preprocessing Multiscale Decomposition Method
    value: None
  LeakyReLU_slope:
    description_CN: LeakyReLU斜率
    description_EN: LeakyReLU Slope
    value: 0.2
  Method:
    description_CN: 项目名称
    description_EN: Project Name
    value: SPS_AD_LLM_Project
  TASK:
    description_CN: 任务类型
    description_EN: Task Type
    value: anomaly_detection
  Version:
    description_CN: 实验编号
    description_EN: Experiment Version
    value: V1.0
  Wavelet_level:
    description_CN: 小波分解层数
    description_EN: Wavelet Decomposition Level
    value: 2
  batch_size:
    description_CN: 批处理大小
    description_EN: Batch Size
    value: 2048
  block_residual:
    description_CN: 是否对空间模块使用残差连接
    description_EN: Whether to use residual connections for the spatial block
    value: false
  data_name:
    description_CN: 数据集名称
    description_EN: Dataset Name
    value: XJTU-SPS for AD
  dataset_tra_d_val:
    description_CN: 训练集与验证集划分比例
    description_EN: Train and Validation Set Split Ratio
    value: 8
  devices:
    description_CN: 使用的设备，GPU编号列表
    description_EN: Device used, GPU number list
    value:
    - 0
  dropout:
    description_CN: Dropout率
    description_EN: Dropout Rate
    value: 0.05
  gradient_clip_val:
    description_CN: 梯度裁剪，防止梯度爆炸
    description_EN: Gradient Clipping to prevent gradient explosion
    value: 100.0
  if_add_work_condition:
    description_CN: 是否使用工况信息也作为输入信息的一部分
    description_EN: Whether to use working condition information as part of input
      information
    value: false
  if_timestamp:
    description_CN: 是否使用时间戳也作为输入信息的一部分
    description_EN: Whether to use timestamp as part of input information
    value: true
  label_len:
    description_CN: Transformers自回归起始标签长度
    description_EN: Transformers Autoregressive Starting Label Length
    value: 1
  lag:
    description_CN: 序列长度
    description_EN: Sequence Length
    value: 96
  lag_step:
    description_CN: 滑动窗口步长
    description_EN: Sliding Window Step
    value: 1
  lr:
    description_CN: 学习率，默认0.0001
    description_EN: Learning Rate, default is 0.0001
    value: 0.0001
  patience:
    description_CN: 连续多少个epoch内loss都没有减下去就停止训练
    description_EN: Number of epochs without loss decrease to stop training
    value: 5
  pred_len:
    description_CN: 预测长度
    description_EN: Prediction Length
    value: 1
  reco_form:
    description_CN: 此参数已弃用
    description_EN: This parameter is deprecated
    value: all_to_all
  result_root_path:
    description_CN: 结果保存路径
    description_EN: Result Save Path
    value: /data/DiYi/MyWorks_Results
  scale:
    description_CN: 是否执行标准化预处理
    description_EN: Whether to perform normalization preprocessing
    value: true
  scheduler:
    description_CN: 使用的学习率衰减策略，可选项有ReduceLROnPlateau、StepLR、ExponentialLR、CosineAnnealingLR、CosineAnnealingWarmRestarts
    description_EN: Learning Rate Decay Strategy used, options include ReduceLROnPlateau,
      StepLR, ExponentialLR, CosineAnnealingLR, CosineAnnealingWarmRestarts
    value: ReduceLROnPlateau
  spatial_block:
    description_CN: 空间信息捕捉模块，目前可选项有GCN、GAT、GIN、SGC、MTGNN、FourierGNN、StemGNN、GraphWaveNet、Nothing
    description_EN: Spatial Information Mining Module, currently available options
      include GCN, GAT, GIN, SGC, MTGNN, FourierGNN, StemGNN, GraphWaveNet, and Nothing.
    value: MTGNN
  temporal_block:
    description_CN: 时间信息捕捉模块，目前可选项有TCN、GRU、Transformer、Informer、Autoformer、PatchTST、DLinear。Nothing
    description_EN: Temporal Information Mining Module, currently available options
      include TCN, GRU, Transformer, Informer, Autoformer, PatchTST, DLinear, and
      Nothing.
    value: Nothing
DLinear: {}
Example_method:
  if_false:
    description_CN: 窗口大小
    description_EN: Window Size
    value: false
  if_true:
    description_CN: 窗口大小
    description_EN: Window Size
    value: true
  list:
    description_CN: 学习率
    description_EN: Learning Rate
    value:
    - 0.01
    - 0.2
  module:
    description_CN: 阈值
    description_EN: Threshold
    value: null
  num_folat:
    description_CN: 步长
    description_EN: Lag
    value: 6.5
  num_int:
    description_CN: 步长
    description_EN: Lag
    value: 96
  path:
    description_CN: 学习率
    description_EN: Learning Rate
    value: /data/DiYi/DATA
  str:
    description_CN: 窗口大小
    description_EN: Window Size
    value: Nothing
FourierGNN: {}
GAT:
  Muti_S_GAT_K:
    description_CN: 多头GAT的头数
    description_EN: Number of heads in Multi-head GAT
    value: 4
  Muti_S_GAT_embed_dim:
    description_CN: GAT的嵌入维度
    description_EN: Embedding dimension for GAT
    value: 96
  use_gatv2:
    description_CN: 是否使用GATv2
    description_EN: Whether to use GATv2
    value: true
GCN:
  GCN_layer_nums:
    description_CN: GCN每层的特征维度列表
    description_EN: List of dimensions for each GCN layer
    value:
    - 96
    - 96
GIN:
  GIN_MLP_layer_num:
    description_CN: GIN公式中的MLP个数
    description_EN: Number of MLPs in GIN formula
    value: 1
  GIN_layer_nums:
    description_CN: GIN每层的特征维度列表
    description_EN: List of dimensions for each GIN layer
    value:
    - 96
    - 96
GRU:
  temporal_block_end_mlp_hidden_dim:
    description_CN: 最后一层用于统一维度的MLP的隐藏层维度
    description_EN: Hidden dimension for MLP mapping to unified dimension after last
      dimension change
    value: 128
  temporal_block_end_mlp_layer_num:
    description_CN: 最后一层用于统一维度的MLP的层数
    description_EN: Number of layers in MLP mapping to unified dimension after last
      dimension change
    value: 2
  transf_GRU_hidden_size:
    description_CN: GRU的h的维度
    description_EN: Hidden dimension for GRU
    value: 64
  transf_GRU_layers:
    description_CN: GRU层数
    description_EN: Number of GRUs
    value: 1
GraphWaveNet: {}
Informer: {}
MLP:
  MLP_hidden_dim:
    description_CN: MLP的隐藏层维度
    description_EN: Hidden dimension for MLP
    value: 96
  MLP_layer_num:
    description_CN: MLP的隐藏层层数
    description_EN: Number of hidden layers in MLP
    value: 2
MTGNN:
  MTGNN_buildA_true:
    description_CN: 是否构建自适应的A矩阵
    description_EN: Whether to build adaptive A matrix
    value: true
  MTGNN_conv_channels:
    description_CN: TC模块输入维度是residual_channels，输出维度是conv_channels
    description_EN: Input dimension for TC module is MTGNN_residual_channels, output
      dimension is MTGNN_conv_channels
    value: 32
  MTGNN_dilation_exponential:
    description_CN: 膨胀指数
    description_EN: Dilation exponential
    value: 1
  MTGNN_end_channels:
    description_CN: end_conv_1的输出维度
    description_EN: Output dimension for end_conv_1
    value: 128
  MTGNN_gcn_depth:
    description_CN: mixprop里面的图卷积深度
    description_EN: Graph convolution depth in mixprop
    value: 2
  MTGNN_gcn_true:
    description_CN: 是否增加GCN层
    description_EN: Whether to add GCN layers
    value: true
  MTGNN_graph_k:
    description_CN: 每个节点几个邻居节点
    description_EN: Number of neighbors for each node
    value: 24
  MTGNN_in_dim:
    description_CN: 输入维度，设置为1即可
    description_EN: Input dimension, set to 1
    value: 1
  MTGNN_layer_norm_affline:
    description_CN: 在层归一化中是否进行逐元素仿射操作
    description_EN: Whether to perform element-wise affine operation in layer normalization
    value: true
  MTGNN_layers:
    description_CN: 多少层GC + TC
    description_EN: Number of layers for GC + TC
    value: 3
  MTGNN_node_embedding:
    description_CN: 节点嵌入的维度
    description_EN: Dimension of node embedding
    value: 192
  MTGNN_propalpha:
    description_CN: Prop alpha，即在混合跳传播中保留根节点原始状态的比例，取值范围在0到1之间
    description_EN: Prop alpha, the proportion of the root node's original state retained
      in mixed jump propagation, range from 0 to 1
    value: 0.05
  MTGNN_residual_channels:
    description_CN: GC模块输入维度是conv_channels，输出维度是residual_channels
    description_EN: Input dimension for GC module is MTGNN_conv_channels, output dimension
      is MTGNN_residual_channels
    value: 32
  MTGNN_skip_channels:
    description_CN: 跳跃连接的输出维度。（输入维度是conv_channels）
    description_EN: Output dimension for skip connection (input dimension is MTGNN_conv_channels)
    value: 64
  MTGNN_tanhalpha:
    description_CN: 生成邻接矩阵时的双曲正切alpha值，alpha控制饱和率
    description_EN: Hyperbolic tangent alpha value for generating adjacency matrix,
      controlling saturation
    value: 3
Nothing: {}
PatchTST: {}
SGC:
  SGC_K:
    description_CN: SGC的K值
    description_EN: K value for SGC
    value: 3
  SGC_hidden_dim:
    description_CN: SGC的隐藏层维度
    description_EN: Hidden dimension for SGC
    value: 96
StemGNN: {}
TCN:
  TCN_kernel_size:
    description_CN: TCN的卷积核大小
    description_EN: Kernel size for TCN
    value: 2
  TCN_num_channels:
    description_CN: TCN每层的通道数列表
    description_EN: List of channels for each TCN layer
    value:
    - 48
    - 48
  temporal_block_end_mlp_hidden_dim:
    description_CN: 最后一层用于统一维度的MLP的隐藏层维度
    description_EN: Hidden dimension for MLP mapping to unified dimension after last
      dimension change
    value: 128
  temporal_block_end_mlp_layer_num:
    description_CN: 最后一层用于统一维度的MLP的层数
    description_EN: Number of layers in MLP mapping to unified dimension after last
      dimension change
    value: 2
Transformer: {}
